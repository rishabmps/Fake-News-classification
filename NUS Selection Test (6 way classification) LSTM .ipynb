{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'LIAR-PLUS' already exists and is not an empty directory.\n",
      "/home/jupyter/LIAR-PLUS/dataset\n",
      "cache\t\t   glove.6B.zip  test.csv    wwm_uncased_L-24_H-1024_A-16\n",
      "glove.6B.100d.txt  labels.csv\t train2.tsv  wwm_uncased_L-24_H-1024_A-16.zip\n",
      "glove.6B.200d.txt  LIAR-PLUS\t train.csv\n",
      "glove.6B.300d.txt  lstm.h5\t val2.tsv\n",
      "glove.6B.50d.txt   test2.tsv\t val.csv\n"
     ]
    }
   ],
   "source": [
    "# Clone the entire repo.\n",
    "!git clone  https://github.com/Tariq60/LIAR-PLUS\n",
    "%cd LIAR-PLUS/dataset\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip glove.6B.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import seaborn as sb\n",
    "\n",
    "\n",
    "# Defining Headers and Condstants like file names\n",
    "\n",
    "test_filename = 'test2.tsv'\n",
    "train_filename = 'train2.tsv'\n",
    "valid_filename = 'val2.tsv'\n",
    "header = ['id','label','statement','subjects','speaker','job_title','state','party','barely_true_counts'\n",
    "         ,'false_counts','half_true_counts','mostly_true_counts','pants_on_fire_counts','venue','justification']\n",
    "\n",
    "# Reading the data \n",
    "\n",
    "train_news = pd.read_csv(train_filename,sep='\\t',names=header)\n",
    "test_news = pd.read_csv(test_filename,sep='\\t',names=header)\n",
    "valid_news = pd.read_csv(valid_filename,sep='\\t',names=header)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subjects</th>\n",
       "      <th>speaker</th>\n",
       "      <th>job_title</th>\n",
       "      <th>state</th>\n",
       "      <th>party</th>\n",
       "      <th>barely_true_counts</th>\n",
       "      <th>false_counts</th>\n",
       "      <th>half_true_counts</th>\n",
       "      <th>mostly_true_counts</th>\n",
       "      <th>pants_on_fire_counts</th>\n",
       "      <th>venue</th>\n",
       "      <th>justification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "      <td>That's a premise that he fails to back up. Ann...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech.</td>\n",
       "      <td>Surovell said the decline of coal \"started whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Denver</td>\n",
       "      <td>Obama said he would have voted against the ame...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        label                                          statement  \\\n",
       "0   2635.json        false  Says the Annies List political group supports ...   \n",
       "1  10540.json    half-true  When did the decline of coal start? It started...   \n",
       "2    324.json  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "\n",
       "                             subjects         speaker             job_title  \\\n",
       "0                            abortion    dwayne-bohac  State representative   \n",
       "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
       "2                      foreign-policy    barack-obama             President   \n",
       "\n",
       "      state       party  barely_true_counts  false_counts  half_true_counts  \\\n",
       "0     Texas  republican                 0.0           1.0               0.0   \n",
       "1  Virginia    democrat                 0.0           0.0               1.0   \n",
       "2  Illinois    democrat                70.0          71.0             160.0   \n",
       "\n",
       "   mostly_true_counts  pants_on_fire_counts            venue  \\\n",
       "0                 0.0                   0.0         a mailer   \n",
       "1                 1.0                   0.0  a floor speech.   \n",
       "2               163.0                   9.0           Denver   \n",
       "\n",
       "                                       justification  \n",
       "0  That's a premise that he fails to back up. Ann...  \n",
       "1  Surovell said the decline of coal \"started whe...  \n",
       "2  Obama said he would have voted against the ame...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_news.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                              2635.json\n",
       "label                                                               false\n",
       "statement               Says the Annies List political group supports ...\n",
       "subjects                                                         abortion\n",
       "speaker                                                      dwayne-bohac\n",
       "job_title                                            State representative\n",
       "state                                                               Texas\n",
       "party                                                          republican\n",
       "barely_true_counts                                                      0\n",
       "false_counts                                                            1\n",
       "half_true_counts                                                        0\n",
       "mostly_true_counts                                                      0\n",
       "pants_on_fire_counts                                                    0\n",
       "venue                                                            a mailer\n",
       "justification           That's a premise that he fails to back up. Ann...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_news.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10240, 15) (1284, 15) (1267, 15)\n"
     ]
    }
   ],
   "source": [
    "print(train_news.shape,valid_news.shape,test_news.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10240 entries, 0 to 10239\n",
      "Data columns (total 15 columns):\n",
      "id                      10240 non-null object\n",
      "label                   10240 non-null object\n",
      "statement               10240 non-null object\n",
      "subjects                10238 non-null object\n",
      "speaker                 10238 non-null object\n",
      "job_title               7343 non-null object\n",
      "state                   8032 non-null object\n",
      "party                   10238 non-null object\n",
      "barely_true_counts      10238 non-null float64\n",
      "false_counts            10238 non-null float64\n",
      "half_true_counts        10238 non-null float64\n",
      "mostly_true_counts      10238 non-null float64\n",
      "pants_on_fire_counts    10238 non-null float64\n",
      "venue                   10138 non-null object\n",
      "justification           10156 non-null object\n",
      "dtypes: float64(5), object(10)\n",
      "memory usage: 1.6+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                         0\n",
       "label                      0\n",
       "statement                  0\n",
       "subjects                   2\n",
       "speaker                    2\n",
       "job_title               2897\n",
       "state                   2208\n",
       "party                      2\n",
       "barely_true_counts         2\n",
       "false_counts               2\n",
       "half_true_counts           2\n",
       "mostly_true_counts         2\n",
       "pants_on_fire_counts       2\n",
       "venue                    102\n",
       "justification             84\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking For nulls\n",
    "train_news.info()\n",
    "train_news.isna().sum()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It can be seen from above analysis, that some rows do not have justification value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new Column by Combining justification and statement made by the speaker\n",
    "# In case justification is not available, text column will then be filled by statement only.\n",
    "\n",
    "train_news['text'] = train_news['statement']+train_news['justification']\n",
    "train_news['text'] = train_news['text'].fillna(train_news['statement'])\n",
    "\n",
    "valid_news['text'] = valid_news['statement']+valid_news['justification']\n",
    "valid_news['text'] = valid_news['text'].fillna(valid_news['statement'])\n",
    "\n",
    "test_news['text'] = test_news['statement']+test_news['justification']\n",
    "test_news['text'] = test_news['text'].fillna(test_news['statement'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['false', 'half-true', 'mostly-true', 'true', 'barely-true',\n",
       "       'pants-fire'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_news['label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a new column 'output' to have a numerical value of the label column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pants-fire': 0, 'false': 1, 'barely-true': 2, 'half-true': 3, 'mostly-true': 4, 'true': 5}\n"
     ]
    }
   ],
   "source": [
    "label_dict = {\"pants-fire\" : 0, \"false\" : 1, \"barely-true\" : 2, \"half-true\" : 3, \"mostly-true\" : 4, \"true\" : 5}\n",
    "print(label_dict)\n",
    "\n",
    "train_news['output'] = train_news['label'].apply(lambda x: label_dict[x])\n",
    "valid_news['output'] = valid_news['label'].apply(lambda x: label_dict[x])\n",
    "test_news['output'] = test_news['label'].apply(lambda x: label_dict[x])\n",
    "\n",
    "num_classes = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Chicago Bears have had more starting quart...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jim Dunnam has not lived in the district he re...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I'm the only person on this stage who has work...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>However, it took $19.5 million in Oregon Lotte...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Says GOP primary opponents Glenn Grothman and ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>For the first time in history, the share of th...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Since 2000, nearly 12 million Americans have s...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>When Mitt Romney was governor of Massachusetts...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The economy bled $24 billion due to the govern...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Most of the (Affordable Care Act) has already ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>In this last election in November, ... 63 perc...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>McCain opposed a requirement that the governme...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>U.S. Rep. Ron Kind, D-Wis., and his fellow Dem...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Water rates in Manila, Philippines, were raise...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Almost 100,000 people left Puerto Rico last ye...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  output\n",
       "0   Says the Annies List political group supports ...       1\n",
       "1   When did the decline of coal start? It started...       3\n",
       "2   Hillary Clinton agrees with John McCain \"by vo...       4\n",
       "3   Health care reform legislation is likely to ma...       1\n",
       "4   The economic turnaround started at the end of ...       3\n",
       "5   The Chicago Bears have had more starting quart...       5\n",
       "6   Jim Dunnam has not lived in the district he re...       2\n",
       "7   I'm the only person on this stage who has work...       3\n",
       "8   However, it took $19.5 million in Oregon Lotte...       3\n",
       "9   Says GOP primary opponents Glenn Grothman and ...       4\n",
       "10  For the first time in history, the share of th...       4\n",
       "11  Since 2000, nearly 12 million Americans have s...       3\n",
       "12  When Mitt Romney was governor of Massachusetts...       1\n",
       "13  The economy bled $24 billion due to the govern...       4\n",
       "14  Most of the (Affordable Care Act) has already ...       2\n",
       "15  In this last election in November, ... 63 perc...       3\n",
       "16  McCain opposed a requirement that the governme...       5\n",
       "17  U.S. Rep. Ron Kind, D-Wis., and his fellow Dem...       2\n",
       "18  Water rates in Manila, Philippines, were raise...       3\n",
       "19  Almost 100,000 people left Puerto Rico last ye...       4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_news[['text','output']][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pants-fire', 'false', 'barely-true', 'half-true', 'mostly-true', 'true'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "MAX_SEQUENCE_LENGTH_OF_TEXT = 1000\n",
    "MAX_NB_WORDS_VOCAB = 200000\n",
    "EMBEDDING_DIM = 100\n",
    "# VALIDATION_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 17528205190168024550\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 12907107328375670030\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 15753943450\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 5432961620172636251\n",
      "physical_device_desc: \"device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 173350850913235619\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTextData(df):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    for i in range(df.text.shape[0]):\n",
    "        texts.append(df.text[i])\n",
    "        labels.append(df.output[i])\n",
    "    return texts,labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the text column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts,train_labels = getTextData(train_news)\n",
    "test_texts,test_labels = getTextData(test_news)\n",
    "val_texts,val_labels = getTextData(valid_news)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS_VOCAB)\n",
    "tokenizer.fit_on_texts(train_texts)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26141 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataPostPadding(texts,labels):\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH_OF_TEXT,padding='post',truncating='post') # Pad input sequences\n",
    "    categorical_labels = to_categorical(np.asarray(labels))\n",
    "    return data , categorical_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding the text column "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pad_sequences is used to ensure that all sequences in a list have the same length. By default this is done by padding 0 in the beginning of each sequence until each sequence has the same length as the longest sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (10240, 1000)\n",
      "Shape of label tensor: (10240, 6)\n"
     ]
    }
   ],
   "source": [
    "train_data,train_labels = getDataPostPadding(train_texts,train_labels)\n",
    "val_data,val_labels = getDataPostPadding(val_texts,val_labels)\n",
    "test_data,test_labels = getDataPostPadding(test_texts,test_labels)\n",
    "print('Shape of data tensor:', train_data.shape)\n",
    "print('Shape of label tensor:', train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ignoring the warnings to keep the notebook clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model for 6-way classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv3D\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.layers import Dense, Embedding, LSTM, GRU,Bidirectional\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 400000 word vectors in Glove.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Using Pre-trained word embeddings\n",
    "GLOVE_DIR = \".\" \n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'), encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    #print(values[1:])\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Total %s word vectors in Glove.' % len(embeddings_index))\n",
    "\n",
    "embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH_OF_TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 1000, 100)         2614200   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1000, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 1000, 32)          16032     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 500, 64)           6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 200)               132000    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 256)               51456     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 2,862,238\n",
      "Trainable params: 2,861,838\n",
      "Non-trainable params: 400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_vecor_length = 32\n",
    "modell = Sequential()\n",
    "# modell.add(Embedding(len(word_index), 100, input_length=1000))\n",
    "modell.add(embedding_layer)\n",
    "modell.add(Dropout(0.2))\n",
    "modell.add(Conv1D(filters=32, kernel_size=5, padding='same', activation='relu'))\n",
    "modell.add(MaxPooling1D(pool_size=2))\n",
    "modell.add(Conv1D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "modell.add(MaxPooling1D(pool_size=2))\n",
    "modell.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)))\n",
    "modell.add(BatchNormalization())\n",
    "modell.add(Dense(256, activation='relu'))\n",
    "modell.add(Dense(128, activation='relu'))\n",
    "modell.add(Dense(64, activation='relu'))\n",
    "modell.add(Dense(6, activation='softmax'))\n",
    "modell.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "               metrics=['categorical_accuracy','binary_accuracy'])\n",
    "print(modell.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10240 samples, validate on 1284 samples\n",
      "Epoch 1/10\n",
      "10240/10240 [==============================] - 163s 16ms/step - loss: 1.7722 - categorical_accuracy: 0.2020 - binary_accuracy: 0.8333 - val_loss: 1.7762 - val_categorical_accuracy: 0.1955 - val_binary_accuracy: 0.8333\n",
      "Epoch 2/10\n",
      "10240/10240 [==============================] - 156s 15ms/step - loss: 1.7446 - categorical_accuracy: 0.2208 - binary_accuracy: 0.8333 - val_loss: 1.7522 - val_categorical_accuracy: 0.2477 - val_binary_accuracy: 0.8333\n",
      "Epoch 3/10\n",
      "10240/10240 [==============================] - 155s 15ms/step - loss: 1.7250 - categorical_accuracy: 0.2362 - binary_accuracy: 0.8333 - val_loss: 1.7308 - val_categorical_accuracy: 0.2383 - val_binary_accuracy: 0.8333\n",
      "Epoch 4/10\n",
      "10240/10240 [==============================] - 156s 15ms/step - loss: 1.6931 - categorical_accuracy: 0.2552 - binary_accuracy: 0.8333 - val_loss: 1.7300 - val_categorical_accuracy: 0.2383 - val_binary_accuracy: 0.8333\n",
      "Epoch 5/10\n",
      "10240/10240 [==============================] - 155s 15ms/step - loss: 1.6578 - categorical_accuracy: 0.2751 - binary_accuracy: 0.8332 - val_loss: 1.7212 - val_categorical_accuracy: 0.2500 - val_binary_accuracy: 0.8333\n",
      "Epoch 6/10\n",
      "10240/10240 [==============================] - 156s 15ms/step - loss: 1.5958 - categorical_accuracy: 0.3048 - binary_accuracy: 0.8332 - val_loss: 1.7564 - val_categorical_accuracy: 0.2500 - val_binary_accuracy: 0.8333\n",
      "Epoch 7/10\n",
      "10240/10240 [==============================] - 155s 15ms/step - loss: 1.5164 - categorical_accuracy: 0.3329 - binary_accuracy: 0.8336 - val_loss: 1.9741 - val_categorical_accuracy: 0.2578 - val_binary_accuracy: 0.8246\n",
      "Epoch 8/10\n",
      "10240/10240 [==============================] - 156s 15ms/step - loss: 1.4451 - categorical_accuracy: 0.3726 - binary_accuracy: 0.8347 - val_loss: 1.7908 - val_categorical_accuracy: 0.2539 - val_binary_accuracy: 0.8305\n",
      "Epoch 9/10\n",
      "10240/10240 [==============================] - 155s 15ms/step - loss: 1.3560 - categorical_accuracy: 0.4139 - binary_accuracy: 0.8386 - val_loss: 2.0299 - val_categorical_accuracy: 0.2477 - val_binary_accuracy: 0.8241\n",
      "Epoch 10/10\n",
      "10240/10240 [==============================] - 156s 15ms/step - loss: 1.2648 - categorical_accuracy: 0.4528 - binary_accuracy: 0.8419 - val_loss: 2.3585 - val_categorical_accuracy: 0.2383 - val_binary_accuracy: 0.8202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdf757f1a20>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the batch size to 16 when running in colab\n",
    "modell.fit(train_data, train_labels, epochs=8, batch_size=64,validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modell.save('Bilstm_6_way.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modell.load_weights('Bilstm_6_way.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Evaluate on test data\n",
      "1267/1267 [==============================] - 2s 1ms/step\n",
      "test loss, test acc: [2.4926290440578205, 0.22178374194402628, 0.813207017359248]\n"
     ]
    }
   ],
   "source": [
    "print('\\n# Evaluate on test data')\n",
    "results = modell.evaluate(test_data, test_labels, batch_size=256)\n",
    "print('test loss, test acc:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
